{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.datasets import imdb\n",
    "from keras.preprocessing import sequence\n",
    "import tensorflow as tf\n",
    "import os\n",
    "import numpy as np\n",
    "\n",
    "VOCAB_SIZE = 88584\n",
    "\n",
    "MAXLEN = 250\n",
    "BATCH_SIZE = 64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "physical_devices = tf.config.list_physical_devices('GPU')\n",
    "tf.config.experimental.set_memory_growth(physical_devices[0], True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "(train_data, train_labels), (test_data, test_labels) = imdb.load_data(num_words= VOCAB_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "189"
     },
     "metadata": {},
     "execution_count": 7
    }
   ],
   "source": [
    "len(train_data[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = sequence.pad_sequences(train_data, MAXLEN)\n",
    "test_data = sequence.pad_sequences(test_data, MAXLEN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Embedding(VOCAB_SIZE, 32),\n",
    "    tf.keras.layers.LSTM(32),\n",
    "    tf.keras.layers.Dense(1, activation='sigmoid')\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Model: \"sequential\"\n_________________________________________________________________\nLayer (type)                 Output Shape              Param #   \n=================================================================\nembedding (Embedding)        (None, None, 32)          2834688   \n_________________________________________________________________\nlstm (LSTM)                  (None, 32)                8320      \n_________________________________________________________________\ndense (Dense)                (None, 1)                 33        \n=================================================================\nTotal params: 2,843,041\nTrainable params: 2,843,041\nNon-trainable params: 0\n_________________________________________________________________\n"
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(\n",
    "    loss='binary_crossentropy',\n",
    "    optimizer='rmsprop',\n",
    "    metrics=['accuracy']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Epoch 1/10\n625/625 [==============================] - 19s 31ms/step - loss: 0.4276 - accuracy: 0.8065 - val_loss: 0.3558 - val_accuracy: 0.8706\nEpoch 2/10\n625/625 [==============================] - 19s 30ms/step - loss: 0.2380 - accuracy: 0.9113 - val_loss: 0.2687 - val_accuracy: 0.8900\nEpoch 3/10\n625/625 [==============================] - 19s 30ms/step - loss: 0.1877 - accuracy: 0.9309 - val_loss: 0.3064 - val_accuracy: 0.8952\nEpoch 4/10\n625/625 [==============================] - 19s 30ms/step - loss: 0.1547 - accuracy: 0.9453 - val_loss: 0.3151 - val_accuracy: 0.8754\nEpoch 5/10\n625/625 [==============================] - 19s 30ms/step - loss: 0.1302 - accuracy: 0.9555 - val_loss: 0.4242 - val_accuracy: 0.8658\nEpoch 6/10\n625/625 [==============================] - 19s 30ms/step - loss: 0.1121 - accuracy: 0.9621 - val_loss: 0.3199 - val_accuracy: 0.8880\nEpoch 7/10\n625/625 [==============================] - 19s 30ms/step - loss: 0.0965 - accuracy: 0.9671 - val_loss: 0.3055 - val_accuracy: 0.8878\nEpoch 8/10\n625/625 [==============================] - 19s 30ms/step - loss: 0.0842 - accuracy: 0.9714 - val_loss: 0.4565 - val_accuracy: 0.8736\nEpoch 9/10\n625/625 [==============================] - 19s 30ms/step - loss: 0.0755 - accuracy: 0.9754 - val_loss: 0.3370 - val_accuracy: 0.8838\nEpoch 10/10\n625/625 [==============================] - 19s 30ms/step - loss: 0.0671 - accuracy: 0.9786 - val_loss: 0.4116 - val_accuracy: 0.8820\n"
    }
   ],
   "source": [
    "history = model.fit(\n",
    "    train_data, \n",
    "    train_labels, \n",
    "    epochs=10,\n",
    "    validation_split=0.2\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "782/782 [==============================] - 8s 11ms/step - loss: 0.5374 - accuracy: 0.8457\n[0.5374112725257874, 0.8457199931144714]\n"
    }
   ],
   "source": [
    "results = model.evaluate(test_data, test_labels)\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/imdb_word_index.json\n1646592/1641221 [==============================] - 0s 0us/step\n"
    }
   ],
   "source": [
    "word_index = imdb.get_word_index()\n",
    "\n",
    "def encode_text(text):\n",
    "    tokens = tf.keras.preprocessing.text.text_to_word_sequence(text)\n",
    "    tokens = [word_index[word] if word in word_index else 0 for word in tokens]\n",
    "    return sequence.pad_sequences([tokens], MAXLEN)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "[  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n   0   0   0   0   0   0   0   0   0  12  17  13  40 477  35 477]\n"
    }
   ],
   "source": [
    "text = \"that movie was just amazing, so amazing\"\n",
    "encoding = encode_text(text)\n",
    "print(encoding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "that movie was just amazing so amazing\n"
    }
   ],
   "source": [
    "reverse_word_index = {value: key for (key, value) in word_index.items()}\n",
    "\n",
    "def decode_integers(integers):\n",
    "    PAD = 0\n",
    "    text = \"\"\n",
    "    for num in integers:\n",
    "        if num != PAD:\n",
    "            text += reverse_word_index[num] + \" \"\n",
    "        \n",
    "    return text[:-1]\n",
    "\n",
    "print(decode_integers(encoding))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "[0.58615786]\n[0.758527]\n"
    }
   ],
   "source": [
    "def predict(text):\n",
    "    encoded_text = encode_text(text)\n",
    "    pred = np.zeros((1, 250))\n",
    "    pred[0] = encoded_text\n",
    "    result = model.predict(pred)\n",
    "    print(result[0])\n",
    "\n",
    "positive_review = \"That movie was so awesome! I really loved it and would watch it again because it was so great\"\n",
    "predict(positive_review)\n",
    "\n",
    "negative_review = \"That movie sucked. I hated it and wouldn't watch it again.\"\n",
    "predict(negative_review)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RNN Play Generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing import sequence\n",
    "import tensorflow as tf\n",
    "import keras\n",
    "import os\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Downloading data from https://storage.googleapis.com/download.tensorflow.org/data/shakespeare.txt\n1122304/1115394 [==============================] - 0s 0us/step\n"
    }
   ],
   "source": [
    "path_to_file = tf.keras.utils.get_file('shakespeare.txt',\n",
    "                                        'https://storage.googleapis.com/download.tensorflow.org/data/shakespeare.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Length of text: 1115394 characters\n"
    }
   ],
   "source": [
    "text = open(path_to_file, 'rb').read().decode(encoding='utf-8')\n",
    "\n",
    "print('Length of text: {} characters'.format(len(text)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "First Citizen:\nBefore we proceed any further, hear me speak.\n\nAll:\nSpeak, speak.\n\nFirst Citizen:\nYou are all resolved rather to die than to famish?\n\nAll:\nResolved. resolved.\n\nFirst Citizen:\nFirst, you know Caius Marcius is chief enemy to the people.\n\n"
    }
   ],
   "source": [
    "print(text[:250])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab = sorted(set(text))\n",
    "# create a mapping\n",
    "char2idx = {u:i for i, u in enumerate(vocab)}\n",
    "idx2char = np.array(vocab)\n",
    "\n",
    "def text_to_int(text):\n",
    "    return np.array([char2idx[c] for c in text])\n",
    "\n",
    "text_as_int = text_to_int(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Text: First Citizen\nEncoding: [18 47 56 57 58  1 15 47 58 47 64 43 52]\n"
    }
   ],
   "source": [
    "print(\"Text:\", text[:13])\n",
    "print(\"Encoding:\", text_to_int(text[:13]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "First Citizen\n"
    }
   ],
   "source": [
    "def int_to_text(ints):\n",
    "    try:\n",
    "        ints = ints.numpy()\n",
    "    except:\n",
    "        pass\n",
    "    return ''.join(idx2char[ints])\n",
    "\n",
    "print(int_to_text(text_as_int[:13]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "seq_length = 100\n",
    "examples_per_epoch = len(text)//(seq_length+1)\n",
    "\n",
    "char_dataset = tf.data.Dataset.from_tensor_slices(text_as_int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "sequences = char_dataset.batch(seq_length + 1, drop_remainder=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_input_target(chunk):\n",
    "    input_text = chunk[:-1]\n",
    "    target_text = chunk[1:]\n",
    "    return input_text, target_text\n",
    "\n",
    "dataset = sequences.map(split_input_target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "\nEXAMPLE\n\nINPUT\nFirst Citizen:\nBefore we proceed any further, hear me speak.\n\nAll:\nSpeak, speak.\n\nFirst Citizen:\nYou\n\nOUTPUT\n\nirst Citizen:\nBefore we proceed any further, hear me speak.\n\nAll:\nSpeak, speak.\n\nFirst Citizen:\nYou \n\nEXAMPLE\n\nINPUT\nare all resolved rather to die than to famish?\n\nAll:\nResolved. resolved.\n\nFirst Citizen:\nFirst, you \n\nOUTPUT\n\nre all resolved rather to die than to famish?\n\nAll:\nResolved. resolved.\n\nFirst Citizen:\nFirst, you k\n"
    }
   ],
   "source": [
    "for x, y in dataset.take(2):\n",
    "    print(\"\\nEXAMPLE\\n\")\n",
    "    print(\"INPUT\")\n",
    "    print(int_to_text(x))\n",
    "    print(\"\\nOUTPUT\\n\")\n",
    "    print(int_to_text(y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 64\n",
    "VOCAB_SIZE = len(vocab)\n",
    "EMBEDDING_DIM = 256\n",
    "RNN_UNITS = 1024\n",
    "\n",
    "BUFFER_SIZE = 10000\n",
    "\n",
    "data = dataset.shuffle(BUFFER_SIZE).batch(BATCH_SIZE, drop_remainder=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model(vocab_size, embedding_dim, rnn_units, batch_size):\n",
    "    model = tf.keras.Sequential([\n",
    "        tf.keras.layers.Embedding(vocab_size, embedding_dim, \n",
    "                                  batch_input_shape=[batch_size, None]),\n",
    "        tf.keras.layers.LSTM(rnn_units,\n",
    "                             return_sequences=True,\n",
    "                             stateful=True,\n",
    "                             recurrent_initializer='glorot_uniform',\n",
    "                             activation='tanh',\n",
    "                             recurrent_activation='sigmoid',\n",
    "                             recurrent_dropout=0),\n",
    "        tf.keras.layers.Dense(vocab_size)\n",
    "    ])\n",
    "    return model\n",
    "\n",
    "model = build_model(VOCAB_SIZE, EMBEDDING_DIM, RNN_UNITS, BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Model: \"sequential_1\"\n_________________________________________________________________\nLayer (type)                 Output Shape              Param #   \n=================================================================\nembedding_1 (Embedding)      (64, None, 256)           16640     \n_________________________________________________________________\nlstm_1 (LSTM)                (64, None, 1024)          5246976   \n_________________________________________________________________\ndense_1 (Dense)              (64, None, 65)            66625     \n=================================================================\nTotal params: 5,330,241\nTrainable params: 5,330,241\nNon-trainable params: 0\n_________________________________________________________________\n"
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "(64, 100, 65) # (batch_size, sequence_length, vocab_size)\n"
    }
   ],
   "source": [
    "for input_example_batch, target_example_batch in data.take(1):\n",
    "    example_batch_predictions = model(input_example_batch)\n",
    "    print(example_batch_predictions.shape, \"# (batch_size, sequence_length, vocab_size)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "64\ntf.Tensor(\n[[[ 8.8019023e-04  3.2530690e-03 -3.2481849e-03 ... -1.7354025e-03\n    6.6066235e-03  1.5243434e-03]\n  [ 4.1613579e-03  2.8104195e-04 -5.7626478e-03 ...  1.7019592e-03\n    9.3478998e-03  5.7835919e-03]\n  [-2.5427202e-05  2.5477884e-03 -4.9664048e-03 ...  3.0876405e-04\n    4.8196274e-03  5.2838326e-03]\n  ...\n  [-2.8815237e-03 -5.3799795e-03  1.3646820e-03 ... -4.5926883e-03\n   -1.7348665e-03  1.1836044e-03]\n  [-2.6868826e-03 -1.3835845e-03 -1.6558128e-03 ... -5.0750249e-03\n    4.4914968e-03  2.7674329e-03]\n  [-1.3152338e-03 -5.4534818e-03 -2.9774010e-04 ... -2.3216968e-03\n    5.4914560e-03  3.8329919e-04]]\n\n [[-5.9693251e-03 -3.7929630e-03 -6.5869873e-04 ...  4.7229361e-03\n   -4.9712318e-03  4.0759076e-03]\n  [-3.9479095e-03 -7.7516483e-03 -6.6291653e-03 ...  7.1468926e-03\n   -1.4603406e-04  2.4550508e-03]\n  [ 3.6079099e-04 -8.1904903e-03 -8.4027939e-04 ...  1.0985746e-02\n    2.8457176e-03 -4.2796024e-04]\n  ...\n  [ 4.3284362e-03  6.3339993e-03  2.6827678e-04 ...  4.7342577e-03\n   -3.3467745e-03  1.6835808e-03]\n  [ 4.6559279e-03  1.4777656e-03 -3.9164796e-03 ...  3.6991411e-03\n   -1.0970643e-02 -1.5421414e-03]\n  [ 5.6667235e-03  6.0336255e-03 -1.9204176e-03 ...  5.7843262e-03\n   -9.3333870e-03  3.2204320e-03]]\n\n [[-8.1237184e-04 -4.1573243e-03 -9.8979694e-04 ...  5.9434166e-03\n   -2.6964599e-03  3.0886850e-03]\n  [-3.6511482e-03 -4.4893641e-03 -1.4755146e-03 ...  6.8745250e-03\n   -8.5592195e-03  3.8988586e-03]\n  [ 9.0846419e-04 -6.8835411e-03  3.6498678e-03 ...  1.1414763e-03\n   -8.6070877e-03  7.0377486e-03]\n  ...\n  [-3.0990418e-03 -8.2082385e-03 -5.2141887e-03 ... -1.1262081e-02\n    6.4400202e-03 -1.6269621e-03]\n  [-8.0979234e-03 -1.1424687e-02 -1.1938832e-02 ... -4.2597251e-03\n    1.1847228e-02 -7.3648910e-03]\n  [ 2.8870988e-03 -3.3212770e-03 -1.6476046e-02 ... -5.5282614e-03\n    1.1045337e-02 -6.9389129e-03]]\n\n ...\n\n [[ 1.0434960e-03  1.6087203e-03  2.2964487e-03 ... -8.9095091e-05\n   -5.5326312e-04  4.6677599e-03]\n  [ 4.3511670e-03 -2.0827088e-03  6.9739390e-03 ... -4.1284855e-03\n   -3.7311949e-03  7.6421881e-03]\n  [ 1.2806832e-03 -3.3239094e-03  1.1675464e-02 ... -6.9577713e-03\n   -2.5913722e-03  7.7221543e-03]\n  ...\n  [-1.4958091e-03  5.3673387e-03 -8.0925440e-03 ... -4.9484596e-03\n    5.4687252e-03  1.5579702e-03]\n  [-1.1951978e-03 -1.5246670e-03 -1.3899218e-02 ... -2.6870938e-04\n    6.3427798e-03  2.9518786e-03]\n  [-1.6813067e-03  4.2531635e-03 -1.1764445e-02 ... -3.0003707e-03\n    9.4141699e-03  3.0065661e-03]]\n\n [[ 3.9939205e-03 -3.3554924e-03  4.8163310e-03 ... -3.2896106e-03\n   -2.6453319e-03  3.7336801e-03]\n  [ 3.9288253e-03  7.3248066e-04  8.4278472e-03 ...  2.9010093e-04\n   -5.9563867e-03  3.0431990e-03]\n  [-3.1172934e-03 -5.5833152e-03  4.5050760e-03 ... -5.0096554e-03\n   -2.0167418e-03 -3.4878764e-03]\n  ...\n  [ 9.7554903e-03  4.9991766e-03 -3.1653324e-03 ...  5.8107707e-03\n   -4.5816670e-03  4.8469771e-03]\n  [ 2.9019159e-03  9.3463548e-03  6.4258464e-04 ...  2.6044932e-03\n   -1.0093498e-02  8.0531919e-03]\n  [ 2.2350114e-03  1.0265179e-02 -1.6516980e-03 ...  1.1693665e-03\n   -1.4675291e-03  7.9047922e-03]]\n\n [[-1.1862386e-03 -1.6994040e-03  5.9522800e-03 ... -3.2669688e-03\n    3.6036992e-04  1.5640897e-03]\n  [ 3.2753875e-03 -4.2922497e-03  8.8335276e-03 ... -5.3895181e-03\n   -2.0814319e-03  4.5443075e-03]\n  [-2.9152271e-03 -8.7224962e-03 -4.8120914e-05 ... -5.2483100e-04\n    5.9295031e-03 -4.4550970e-03]\n  ...\n  [ 1.3463812e-02  2.0146980e-03 -5.8126412e-03 ... -3.7283199e-03\n    7.4814889e-03 -4.5166602e-03]\n  [ 6.2145148e-03 -4.8310868e-03 -6.2565310e-03 ... -8.2261721e-03\n    7.6032546e-03 -8.3594425e-03]\n  [ 5.1440038e-03 -7.2419690e-03 -5.9077698e-03 ... -1.4040666e-04\n    2.1751164e-03 -2.4973864e-03]]], shape=(64, 100, 65), dtype=float32)\n"
    }
   ],
   "source": [
    "print(len(example_batch_predictions))\n",
    "print(example_batch_predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "100\ntf.Tensor(\n[[ 8.8019023e-04  3.2530690e-03 -3.2481849e-03 ... -1.7354025e-03\n   6.6066235e-03  1.5243434e-03]\n [ 4.1613579e-03  2.8104195e-04 -5.7626478e-03 ...  1.7019592e-03\n   9.3478998e-03  5.7835919e-03]\n [-2.5427202e-05  2.5477884e-03 -4.9664048e-03 ...  3.0876405e-04\n   4.8196274e-03  5.2838326e-03]\n ...\n [-2.8815237e-03 -5.3799795e-03  1.3646820e-03 ... -4.5926883e-03\n  -1.7348665e-03  1.1836044e-03]\n [-2.6868826e-03 -1.3835845e-03 -1.6558128e-03 ... -5.0750249e-03\n   4.4914968e-03  2.7674329e-03]\n [-1.3152338e-03 -5.4534818e-03 -2.9774010e-04 ... -2.3216968e-03\n   5.4914560e-03  3.8329919e-04]], shape=(100, 65), dtype=float32)\n"
    }
   ],
   "source": [
    "pred = example_batch_predictions[0]\n",
    "print(len(pred))\n",
    "print(pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "65\ntf.Tensor(\n[ 8.80190230e-04  3.25306901e-03 -3.24818492e-03  7.60958763e-04\n -4.88198409e-03  5.26125031e-03  5.57917450e-03 -4.24757542e-04\n  2.06701946e-03 -1.46621803e-03  3.01002152e-03 -3.65632400e-03\n -3.25845880e-03  1.88306440e-03  1.20489276e-04  5.50129078e-03\n -6.77184016e-03  1.68993487e-04  4.11393400e-03 -4.77781170e-04\n  1.12394616e-03 -1.92413083e-03 -1.61039445e-03 -3.30121373e-03\n -1.00579648e-03  7.70861236e-03 -4.61335003e-04  1.17314281e-04\n  5.30266203e-03  2.19720270e-04 -3.04426439e-03  3.68219777e-03\n  9.79654770e-03  7.21582095e-04 -2.55469070e-03 -2.45107105e-03\n -2.72494799e-04 -2.84120720e-03  3.96092003e-03  6.65480364e-03\n  1.18306279e-03  7.32302759e-03 -1.64300518e-03  2.42383545e-03\n  9.65212472e-03  4.74687607e-04  1.79817516e-03 -1.75667508e-03\n  7.72410305e-04  4.43422515e-03 -3.34217073e-03  2.79051776e-04\n  5.77395968e-03 -4.28572483e-03  4.47732222e-04 -2.63702660e-03\n -7.96843553e-04  4.11505718e-03 -2.00894987e-03  2.13737076e-05\n -4.38132044e-03  3.03241727e-03 -1.73540250e-03  6.60662353e-03\n  1.52434339e-03], shape=(65,), dtype=float32)\n"
    }
   ],
   "source": [
    "time_pred = pred[0]\n",
    "print(len(time_pred))\n",
    "print(time_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "\"sC-hnvnR?RMSIrYqsrl;MLHZ.poE&xXM$S!M.ffJWrZD$gSoQi!&gaRBWt:mxAFd,hTgIXUkuF'xxSk.GIrVOHUtEghnamFbH'sB\""
     },
     "metadata": {},
     "execution_count": 42
    }
   ],
   "source": [
    "sampled_indices = tf.random.categorical(pred, num_samples=1)\n",
    "\n",
    "sampled_indices = np.reshape(sampled_indices, (1, -1))[0]\n",
    "predicted_chars = int_to_text(sampled_indices)\n",
    "\n",
    "predicted_chars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss(labels, logits):\n",
    "    return tf.keras.losses.sparse_categorical_crossentropy(labels, logits, from_logits=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile('adam', loss=loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint_dir = './training_checkpoints'\n",
    "\n",
    "checkpoint_prefix = os.path.join(checkpoint_dir, \"ckpt_{epoch}\")\n",
    "\n",
    "checkpoint_callback = tf.keras.callbacks.ModelCheckpoint(\n",
    "    filepath=checkpoint_prefix,\n",
    "    save_weights_only=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Epoch 1/40\n172/172 [==============================] - 10s 56ms/step - loss: 2.5447\nEpoch 2/40\n172/172 [==============================] - 10s 57ms/step - loss: 1.8499\nEpoch 3/40\n172/172 [==============================] - 10s 57ms/step - loss: 1.6099\nEpoch 4/40\n172/172 [==============================] - 10s 57ms/step - loss: 1.4845\nEpoch 5/40\n172/172 [==============================] - 10s 58ms/step - loss: 1.4083\nEpoch 6/40\n172/172 [==============================] - 10s 58ms/step - loss: 1.3528\nEpoch 7/40\n172/172 [==============================] - 10s 58ms/step - loss: 1.3084\nEpoch 8/40\n172/172 [==============================] - 10s 58ms/step - loss: 1.2678\nEpoch 9/40\n172/172 [==============================] - 10s 59ms/step - loss: 1.2297\nEpoch 10/40\n172/172 [==============================] - 10s 58ms/step - loss: 1.1940\nEpoch 11/40\n172/172 [==============================] - 10s 58ms/step - loss: 1.1561\nEpoch 12/40\n172/172 [==============================] - 10s 58ms/step - loss: 1.1174\nEpoch 13/40\n172/172 [==============================] - 10s 58ms/step - loss: 1.0784\nEpoch 14/40\n172/172 [==============================] - 10s 58ms/step - loss: 1.0371\nEpoch 15/40\n172/172 [==============================] - 10s 58ms/step - loss: 0.9959\nEpoch 16/40\n172/172 [==============================] - 10s 58ms/step - loss: 0.9530\nEpoch 17/40\n172/172 [==============================] - 10s 59ms/step - loss: 0.9119\nEpoch 18/40\n172/172 [==============================] - 10s 58ms/step - loss: 0.8703\nEpoch 19/40\n172/172 [==============================] - 10s 58ms/step - loss: 0.8310\nEpoch 20/40\n172/172 [==============================] - 10s 59ms/step - loss: 0.7932\nEpoch 21/40\n172/172 [==============================] - 10s 60ms/step - loss: 0.7598\nEpoch 22/40\n172/172 [==============================] - 10s 60ms/step - loss: 0.7251\nEpoch 23/40\n172/172 [==============================] - 10s 60ms/step - loss: 0.6954\nEpoch 24/40\n172/172 [==============================] - 10s 60ms/step - loss: 0.6689\nEpoch 25/40\n172/172 [==============================] - 10s 59ms/step - loss: 0.6431\nEpoch 26/40\n172/172 [==============================] - 10s 60ms/step - loss: 0.6213\nEpoch 27/40\n172/172 [==============================] - 10s 60ms/step - loss: 0.6020\nEpoch 28/40\n172/172 [==============================] - 10s 59ms/step - loss: 0.5831\nEpoch 29/40\n172/172 [==============================] - 10s 60ms/step - loss: 0.5661\nEpoch 30/40\n172/172 [==============================] - 10s 59ms/step - loss: 0.5525\nEpoch 31/40\n172/172 [==============================] - 10s 60ms/step - loss: 0.5398\nEpoch 32/40\n172/172 [==============================] - 10s 59ms/step - loss: 0.5263\nEpoch 33/40\n172/172 [==============================] - 10s 59ms/step - loss: 0.5163\nEpoch 34/40\n172/172 [==============================] - 10s 59ms/step - loss: 0.5067\nEpoch 35/40\n172/172 [==============================] - 10s 59ms/step - loss: 0.4967\nEpoch 36/40\n172/172 [==============================] - 10s 59ms/step - loss: 0.4885\nEpoch 37/40\n172/172 [==============================] - 10s 59ms/step - loss: 0.4797\nEpoch 38/40\n172/172 [==============================] - 10s 61ms/step - loss: 0.4733\nEpoch 39/40\n172/172 [==============================] - 10s 60ms/step - loss: 0.4671\nEpoch 40/40\n172/172 [==============================] - 10s 60ms/step - loss: 0.4624\n"
    }
   ],
   "source": [
    "history = model.fit(data, epochs=40, callbacks=[checkpoint_callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = build_model(VOCAB_SIZE, EMBEDDING_DIM, RNN_UNITS, batch_size=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.load_weights(tf.train.latest_checkpoint(checkpoint_dir))\n",
    "model.build(tf.TensorShape([1, None]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_text(model, start_string):\n",
    "    num_generate = 800\n",
    "\n",
    "    input_eval = [char2idx[s] for s in start_string]\n",
    "    input_eval = tf.expand_dims(input_eval, 0)\n",
    "\n",
    "    text_generated = []\n",
    "\n",
    "    temperature = 1.0\n",
    "\n",
    "    model.reset_states()\n",
    "    for i in range(num_generate):\n",
    "        predictions = model(input_eval)\n",
    "\n",
    "        predictions = tf.squeeze(predictions, 0)\n",
    "\n",
    "        predictions = predictions / temperature\n",
    "        predicted_id = tf.random.categorical(predictions, num_samples=1)[-1, 0].numpy()\n",
    "\n",
    "        input_eval = tf.expand_dims([predicted_id], 0)\n",
    "\n",
    "        text_generated.append(idx2char[predicted_id])\n",
    "\n",
    "    return start_string + ''.join(text_generated)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "romeop her, out, a bannerd, in the virtues\nWhere the inf rouge must be a practise.\nWho knew me an hundred with a soul of his action\nAt our beauty's sore so well they are fled,\nAs well the four access of death,\nAnd not be bureful age, leanness, but the gires is but grows. Stand, fearful!\nThou hast deliver'd to he is yours;--\nWherein these blows being care to redeem me? so, if thou darest,\nTo God and man, you lie in vieward bill to reason by\nAnd kiss her lip? and give our fathers,\nYet cannot name poison from sour mind: away!\nTell me, if once be full I joy,\nCome, faints, a royal stats to rise;\nYour fire-died, now thou lay and full of\ngreat traffrow stices of what faults may call thee first and glodize\nThe knave my brother; therefore I compland;\nFor they one pleasant slander'd love.\nMost migate mou\n"
    }
   ],
   "source": [
    "inp = input(\"Type a starting string: \")\n",
    "print(generate_text(model, inp))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Model: \"sequential_2\"\n_________________________________________________________________\nLayer (type)                 Output Shape              Param #   \n=================================================================\nembedding_2 (Embedding)      (1, None, 256)            16640     \n_________________________________________________________________\nlstm_2 (LSTM)                (1, None, 1024)           5246976   \n_________________________________________________________________\ndense_2 (Dense)              (1, None, 65)             66625     \n=================================================================\nTotal params: 5,330,241\nTrainable params: 5,330,241\nNon-trainable params: 0\n_________________________________________________________________\n"
    }
   ],
   "source": [
    "model.summary()"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": 3
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python_defaultSpec_1593980129096",
   "display_name": "Python 3.8.3 64-bit"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}